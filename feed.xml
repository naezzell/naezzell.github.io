<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://naezzell.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://naezzell.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-16T23:05:19+00:00</updated><id>https://naezzell.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Entry-wise vector and matrix derivatives</title><link href="https://naezzell.github.io/blog/2021/entrywise-matrix-derivative/" rel="alternate" type="text/html" title="Entry-wise vector and matrix derivatives"/><published>2021-08-30T00:00:00+00:00</published><updated>2021-08-30T00:00:00+00:00</updated><id>https://naezzell.github.io/blog/2021/entrywise-matrix-derivative</id><content type="html" xml:base="https://naezzell.github.io/blog/2021/entrywise-matrix-derivative/"><![CDATA[<p>During my time at USC, I took a machine learning course in Fall 2021. In the first homework assignment, we were given</p> <p>\begin{equation} f(\boldsymbol{x}) = \boldsymbol{x}^T A \boldsymbol{x} + \boldsymbol{b}^T \boldsymbol{x} \end{equation} for $\boldsymbol{x} \in \mathbb{R}^n$, $\boldsymbol{x}^T$ is the tranpose of this vector, and hence $f(\boldsymbol{x}) : \mathbb{R}^n \to \mathbb{R}$ is a scalar function with vector inputs.</p> <p>We were then asked to compute \begin{equation} \frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}}, \qquad \frac{\partial f(\boldsymbol{x})}{\partial A}, \end{equation} which many people in the course found confusing notation since, at the end of the day,</p> <blockquote> <p>derivatives always act on scalar functions.</p> </blockquote> <p>The confusion is merely notational, as we shall see. In fact, this is a great example of the concepts of overloading notation and abuse of notation (hence the tags).</p> <hr/> <h2 id="vector-derivative-gradient-entry-wise">Vector derivative (gradient, entry-wise)</h2> <p>Since $f$ depends on the scalar variables $x_1, x_2, \ldots, x_n$, the most natural thing to do is to take all first partial derivatives:</p> <p>\begin{equation} \label{eq:guess-for-first-der} \frac{\partial f(\boldsymbol{x})}{\partial x_1}, \frac{\partial f(\boldsymbol{x})}{\partial x_2}, \ldots, \frac{\partial f(\boldsymbol{x})}{\partial x_n}. \end{equation} Each term in Eq.\eqref{eq:guess-for-first-der} is an ordinary scalar derivative: we differentiate a scalar function with respect to a scalar variable.</p> <p>A convenient way to store these derivatives is in a vector, and that is exactly what “derivative with respect to a vector” means:</p> <p>\begin{equation} \label{eq:vec-div-def} \frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}} \equiv \left( \frac{\partial f(\boldsymbol{x})}{\partial x_1}, \frac{\partial f(\boldsymbol{x})}{\partial x_2}, \ldots, \frac{\partial f(\boldsymbol{x})}{\partial x_n} \right)^T, \end{equation} where $\equiv$ is notation meaning ``defines” which is defining the notation for the vector derivative in this case. In fact, this is just the familiar [<a href="https://en.wikipedia.org/wiki/Gradient">gradient</a>] from multivariable calculus disguised by overloaded notation/an <em>abuse of notation</em>. Oh, and the tranpose is just to make this row vector a column vector—a minor detail for keeping track of dimensions properly.</p> <p>Thus your initial intuition that might have said “you can’t take a derivative with respect to a vector” is correct. The notation here simply instructs you to take all scalar derivatives and stack them into a vector, aka the gradient.</p> <hr/> <h2 id="matrix-derivative-entry-wise">Matrix derivative (entry-wise)</h2> <p>In exact analogy,</p> \[\frac{\partial f}{\partial A} = \left( \begin{array}{cccc} \frac{\partial f}{\partial A_{11}} &amp; \frac{\partial f}{\partial A_{12}} &amp; \cdots &amp; \frac{\partial f}{\partial A_{1n}} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f}{\partial A_{n1}} &amp; \frac{\partial f}{\partial A_{n2}} &amp; \cdots &amp; \frac{\partial f}{\partial A_{nn}} \end{array} \right).\] <p>That is: take the scalar derivative with respect to each entry $A_{ij}$ and arrange the results into a matrix.</p> <hr/> <h2 id="a-concrete-2-times-2-example">A concrete $2 \times 2$ example</h2> <p>To drive the point home, let’s compute $\frac{\partial f(\boldsymbol{x})}{\partial x_1}$ for a $2 \times 2$ example. Suppose</p> \[\begin{aligned} f(\mathbf{x}) &amp;= (x_1, x_2) \left( \begin{array}{cc} A_{11} &amp; A_{12} \\ A_{21} &amp; A_{22} \end{array} \right) \left( \begin{array}{c} x_1 \\ x_2 \end{array} \right) \\ &amp;= A_{11} x_1^2 + A_{12} x_1 x_2 + A_{21} x_1 x_2 + A_{22} x_2^2. \end{aligned}\] <p>Then</p> \[\frac{\partial f}{\partial x_1} = 2 A_{11} x_1 + A_{12} x_2 + A_{21} x_2.\] <p>With this (and the analogous calculation for $\frac{\partial f}{\partial x_2}$), we have computed $\partial f / \partial \boldsymbol{x}$ for this $2 \times 2$ example. A similar exercise yields $\partial f / \partial A$. By writing out $f(\boldsymbol{x})$ for general $n$ or pattern matching by direct computation on the $2 \times 2, 3 \times 3, \ldots, n \times n$ answers, we can thus compute $\partial f / \partial \boldsymbol{x}$ and $\partial f / \partial A$ for general $n$, which we leave as an exercise given its origin.</p>]]></content><author><name></name></author><category term="math-notes"/><category term="abuse-of-notation"/><category term="operator-overloading"/><category term="calculus"/><category term="linear-algebra"/><summary type="html"><![CDATA[Understanding derivatives with respect to vectors and matrices via entry-wise differentiation.]]></summary></entry></feed>